{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/thelokeshgoel00/youtube-reinforcement/blob/master/Reinforcement%20L1/ReInforcementLearningInCartPole.ipynb\n",
    "import numpy as np\n",
    "import gym\n",
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_games():\n",
    "    for episode in range(10):\n",
    "        env.reset()\n",
    "        \n",
    "        for t in range(500):\n",
    "            env.render()\n",
    "            action=env.action_space.sample()\n",
    "            next_state,reward,done,info=env.step(action)\n",
    "#             print(t,next_state,done,info,action)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "    env.close()\n",
    "\n",
    "random_games()\n",
    "            \n",
    "    \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_data(env):\n",
    "    num_trials = 10000\n",
    "    min_score = 100\n",
    "    sim_steps = 300\n",
    "    trainingX,trainingY = [],[]\n",
    "    scores = []\n",
    "    for trial in range(num_trials):\n",
    "        observation = env.reset()\n",
    "        score = 0\n",
    "        training_sampleX,training_sampleY = [],[]        \n",
    "        \n",
    "        for step in range(sim_steps):          \n",
    "#             env.render()\n",
    "            action = np.random.randint(0,2) # left or right\n",
    "            one_hot_action = np.zeros(2)\n",
    "            one_hot_action[action] = 1\n",
    "            training_sampleX.append(observation)\n",
    "            training_sampleY.append(one_hot_action)\n",
    "            observation , reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        if score>min_score:\n",
    "            scores.append(score)\n",
    "            trainingX+=training_sampleX\n",
    "            trainingY+=training_sampleY\n",
    "            \n",
    "        clear_output(wait=True)\n",
    "        print(\"Episodes: \",trial)\n",
    "        \n",
    "    trainingX,trainingY = np.array(trainingX), np.array(trainingY)\n",
    "    print(\"Average: {}\".format(np.mean(scores)))\n",
    "    print(\"Median: {}\".format(np.median(scores)))\n",
    "#     env.close()\n",
    "    return trainingX,trainingY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episodes:  9978\n"
     ]
    }
   ],
   "source": [
    "x_train,y_train=gather_data(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(416, 4)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n"
     ]
    }
   ],
   "source": [
    "TRAIN_SIZE=400\n",
    "xx_train,xx_test=x_train[:TRAIN_SIZE],x_train[TRAIN_SIZE:]\n",
    "yy_train,yy_test=y_train[:TRAIN_SIZE],y_train[TRAIN_SIZE:]\n",
    "print(yy_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256,input_shape=(4,),activation='relu'))\n",
    "    model.add(Dropout(0.5))   \n",
    "\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))   \n",
    "    \n",
    "\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(128,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(2, activation='linear'))\n",
    "    \n",
    "\n",
    "    model.compile(loss='mse',optimizer=Adam(lr=0.01),metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 400 samples\n",
      "Epoch 1/20\n",
      "400/400 [==============================] - 1s 3ms/sample - loss: 0.4930 - accuracy: 0.5100\n",
      "Epoch 2/20\n",
      "400/400 [==============================] - 0s 285us/sample - loss: 0.2883 - accuracy: 0.4900\n",
      "Epoch 3/20\n",
      "400/400 [==============================] - 0s 297us/sample - loss: 0.2599 - accuracy: 0.5550\n",
      "Epoch 4/20\n",
      "400/400 [==============================] - 0s 315us/sample - loss: 0.2688 - accuracy: 0.5775\n",
      "Epoch 5/20\n",
      "400/400 [==============================] - 0s 295us/sample - loss: 0.2520 - accuracy: 0.5625\n",
      "Epoch 6/20\n",
      "400/400 [==============================] - 0s 310us/sample - loss: 0.2560 - accuracy: 0.5200\n",
      "Epoch 7/20\n",
      "400/400 [==============================] - 0s 292us/sample - loss: 0.2572 - accuracy: 0.5425\n",
      "Epoch 8/20\n",
      "400/400 [==============================] - 0s 297us/sample - loss: 0.2466 - accuracy: 0.5625\n",
      "Epoch 9/20\n",
      "400/400 [==============================] - 0s 310us/sample - loss: 0.2485 - accuracy: 0.6000\n",
      "Epoch 10/20\n",
      "400/400 [==============================] - 0s 295us/sample - loss: 0.2491 - accuracy: 0.5875\n",
      "Epoch 11/20\n",
      "400/400 [==============================] - 0s 290us/sample - loss: 0.2588 - accuracy: 0.5475\n",
      "Epoch 12/20\n",
      "400/400 [==============================] - 0s 277us/sample - loss: 0.2520 - accuracy: 0.5350\n",
      "Epoch 13/20\n",
      "400/400 [==============================] - 0s 280us/sample - loss: 0.2571 - accuracy: 0.5600\n",
      "Epoch 14/20\n",
      "400/400 [==============================] - 0s 297us/sample - loss: 0.2543 - accuracy: 0.4950\n",
      "Epoch 15/20\n",
      "400/400 [==============================] - 0s 307us/sample - loss: 0.2520 - accuracy: 0.5650\n",
      "Epoch 16/20\n",
      "400/400 [==============================] - 0s 295us/sample - loss: 0.2508 - accuracy: 0.5375\n",
      "Epoch 17/20\n",
      "400/400 [==============================] - 0s 292us/sample - loss: 0.2499 - accuracy: 0.5425\n",
      "Epoch 18/20\n",
      "400/400 [==============================] - 0s 285us/sample - loss: 0.2551 - accuracy: 0.5375 - loss: 0.2605 - accuracy: 0.53\n",
      "Epoch 19/20\n",
      "400/400 [==============================] - 0s 332us/sample - loss: 0.2564 - accuracy: 0.5575\n",
      "Epoch 20/20\n",
      "400/400 [==============================] - 0s 312us/sample - loss: 0.2512 - accuracy: 0.5250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d3602ebec8>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(xx_train,yy_train,epochs=20)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "16/16 [==============================] - 0s 10ms/sample - loss: 0.2325 - accuracy: 0.5625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23254814743995667, 0.5625]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(xx_test,yy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps  239  Score  239.0\n",
      "Steps  305  Score  305.0\n",
      "Steps  348  Score  348.0\n"
     ]
    }
   ],
   "source": [
    "num_trials = 3\n",
    "\n",
    "\n",
    "for trial in range(num_trials):\n",
    "    observation = env.reset()\n",
    "    score = 0\n",
    "    done=False\n",
    "    steps=0\n",
    "    \n",
    "    while not done:        \n",
    "        env.render()\n",
    "        predict=model.predict(observation.reshape(-1,4))\n",
    "        action = np.argmax(predict)\n",
    "        observation,reward,done,info = env.step(action)\n",
    "        steps+=1\n",
    "        score+=reward\n",
    "    print(\"Steps \",steps,\" Score \",score)\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using DOT  (100% accuracy)\n",
    "\n",
    "## https://www.youtube.com/watch?v=Bi-CKm9zS9c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best length:  63.81\n",
      "Best length:  237.13\n",
      "Best length:  237.13\n",
      "Best length:  301.51\n",
      "Best length:  301.51\n",
      "Best length:  301.51\n",
      "Best length:  301.51\n",
      "Best length:  301.51\n",
      "Best length:  301.51\n",
      "Best length:  500.0\n"
     ]
    }
   ],
   "source": [
    "best_length=0\n",
    "episode_lengths=[]\n",
    "\n",
    "best_weight=np.zeros(4)\n",
    "\n",
    "for agent in range(100):\n",
    "    new_weight=np.random.uniform(-1.0,1.0,4)\n",
    "    \n",
    "    length=[]\n",
    "    for game in range(100):\n",
    "        observation=env.reset()\n",
    "        done=False\n",
    "        step=0\n",
    "        \n",
    "        while not done:\n",
    "            step+=1\n",
    "            action=1 if np.dot(observation,new_weight)>0 else 0\n",
    "            observation,reward,done,_=env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                break\n",
    "        length.append(step)\n",
    "    average_length=float(sum(length)/len(length))\n",
    "    \n",
    "    if average_length>best_length:\n",
    "        best_length=average_length\n",
    "        best_weight=new_weight\n",
    "    episode_lengths.append(average_length)\n",
    "    if agent%10==0:\n",
    "        print(\"Best length: \",best_length)\n",
    "\n",
    "            \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Record as a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for recording a video, need to install ffmpeg :   conda install -c conda-forge ffmpeg\n",
    "from gym import wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game lasted  500\n"
     ]
    }
   ],
   "source": [
    "done=False\n",
    "cnt=0\n",
    "env=wrappers.Monitor(env,\"Video\",force=True)\n",
    "observation=env.reset()\n",
    "\n",
    "while not done:\n",
    "    action=1 if np.dot(observation,best_weight)>0 else 0\n",
    "    observation,reward,done,_=env.step(action)\n",
    "    \n",
    "    cnt+=1\n",
    "    if done:\n",
    "        break\n",
    "        \n",
    "env.close()\n",
    "    \n",
    "print(\"Game lasted \",cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
