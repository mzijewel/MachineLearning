{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mzijewel/MachineLearning/blob/master/Supervised/Classifcation/Cifar10PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fsT3-rzvIIT4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2afQfqrMbMau",
        "outputId": "78cf51f7-e079-4016-b1b2-834383bcf148"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "     ])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "6THcCA0nIlO_",
        "outputId": "ff95d019-6377-4907-f723-b9d4b7e723b7"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(batch_size)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vjjk55mNIJF",
        "outputId": "a741d6a4-0f5b-4aad-9d9b-a24aaa2ef246"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def flatten_layer_factor(input_size,filter,padding,stride,max_pool,max_pool_count):\n",
        "    W=input_size\n",
        "    F=filter\n",
        "    P=padding\n",
        "    S=stride\n",
        "\n",
        "    for _ in range(max_pool_count):\n",
        "        result=(W-F+2*P)*S+1\n",
        "        result=result/max_pool\n",
        "        W=result\n",
        "\n",
        "    return int(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "factor=flatten_layer_factor(32,5,0,1,2,2)\n",
        "factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxsRX5aDI3zA"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5) # input (RGB channel) = 3, Out = 6, Filter = 5\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5) # input 16 must be same as prev out \n",
        "        self.fc1 = nn.Linear(16 * factor * factor, 120) # 16*5*5 using layer count eqn (W-F+2P)S+1\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
        "        # x = x.view(-1, 16*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVKjt-vsghtI"
      },
      "outputs": [],
      "source": [
        "model = Model().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKJMmR6aI7i2"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgc7W33QI-O_",
        "outputId": "3c87104c-e57c-4acb-9419-4363e41dc17a"
      },
      "outputs": [],
      "source": [
        "def train(num_epch):\n",
        "  start_time=time.time()\n",
        "  model.train()\n",
        "  for epoch in range(num_epch):  # You can adjust the number of epochs\n",
        "      running_loss = 0.0\n",
        "      for i, data in enumerate(trainloader, 0):\n",
        "          inputs, labels = data[0].to(device),data[1].to(device)\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item()\n",
        "          if i % 2000 == 1999:  # print every 2000 mini-batches\n",
        "              print('[%d, %5d] loss: %.3f' %\n",
        "                    (epoch + 1, i + 1, running_loss / 2000))\n",
        "              running_loss = 0.0\n",
        "\n",
        "  exec_time=time.time()-start_time\n",
        "  print(f'Finished Training: {exec_time:.2f}s')\n",
        "\n",
        "\n",
        "def test_accuracy():\n",
        "  global score\n",
        "  model.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device),data[1].to(device)\n",
        "          # calculate outputs by running images through the network\n",
        "          outputs = model(images)\n",
        "          # the class with the highest energy is what we choose as prediction\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += labels.size(0)\n",
        "          correct += (predicted == labels).sum().item()\n",
        "\n",
        "  score=100 * correct // total\n",
        "  print(f'Accuracy of the network on the 10000 test images: {score} %')\n",
        "\n",
        "def test_accuracy_all():\n",
        "\n",
        "  # prepare to count predictions for each class\n",
        "  correct_pred = {classname: 0 for classname in classes}\n",
        "  total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "  # again no gradients needed\n",
        "  with torch.no_grad():\n",
        "      for data in testloader:\n",
        "          images, labels = data[0].to(device),data[1].to(device)\n",
        "          outputs = model(images)\n",
        "          _, predictions = torch.max(outputs, 1)\n",
        "          # collect the correct predictions for each class\n",
        "          for label, prediction in zip(labels, predictions):\n",
        "              if label == prediction:\n",
        "                  correct_pred[classes[label]] += 1\n",
        "              total_pred[classes[label]] += 1\n",
        "\n",
        "\n",
        "  # print accuracy for each class\n",
        "  for classname, correct_count in correct_pred.items():\n",
        "      accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "      print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')\n",
        "\n",
        "\n",
        "def predict(model,img_path):\n",
        "  with torch.no_grad():\n",
        "    img=Image.open(img_path).resize((32,32))\n",
        "    # img_tns=torchvision.transforms.ToTensor()(img).unsqueeze(0)\n",
        "    img_tns=transform(img).unsqueeze(0)\n",
        "    result=model(img_tns)\n",
        "    probabilities=torch.softmax(result[0],dim=0)\n",
        "    # max_indx=torch.argmax(probabilities)\n",
        "    max_val,max_indx=torch.max(probabilities,dim=0)\n",
        "    item=classes[max_indx]\n",
        "    print(f'{img_path:10s} : {item:5s} : {max_val*100:0.2f}% : index {max_indx}')\n",
        "\n",
        "\n",
        "def save_weight():\n",
        "  path=f'm-{score}.pth'\n",
        "  torch.save(model.state_dict(), path)\n",
        "\n",
        "def load_weight(path):\n",
        "  model = Model()\n",
        "  model.load_state_dict(torch.load(path))\n",
        "  return model\n",
        "\n",
        "def save_model(name):\n",
        "  model.eval()\n",
        "  input=torch.randn(1,3,32,32)\n",
        "  m=torch.jit.trace(model.to(torch.device('cpu')),input)\n",
        "  torch.jit.save(m,name)\n",
        "  # s=optimize_for_mobile(m)\n",
        "  # s._save_for_lite_interpreter('m10.ptl') # this prediction is not correct\n",
        "\n",
        "\n",
        "def load_model(path):\n",
        "  model=torch.jit.load(path)\n",
        "  model.eval()\n",
        "  # count=sum(p.numel() for p in model.parameters())\n",
        "  # print(f\"prams: {count}\")\n",
        "  return model\n",
        "\n",
        "def test_model(path):\n",
        "  model=load_model(path)\n",
        "  imgs=[\"car.jpeg\",\"cat.jpg\",\"deer.jpeg\",\"dog.jpg\"]\n",
        "  for img in imgs:\n",
        "    predict(model,f'data/img/{img}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train(2)\n",
        "test_accuracy()\n",
        "# 4 -> 71"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m=f'm-{score}.pt'\n",
        "save_model(m)\n",
        "test_model(m)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_weight()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPKRQ4IpEbYRbtzeiZmzgsr",
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
